---
layout:     post
title:      "Fast R-CNN"
subtitle:   ""
date:       2017-12-12
author:     "thidtc"
header-img: "img/2017-bg.jpg"
catalog: true
mathjax: true
tags:
    - object detection
    - RCNN
---

### 1. 来源

ICCV 2015

### 2. 作者信息

Ross Girshick
Microsoft Research
rbg@microsoft.com 

### 3. 源代码

https: //github.com/rbgirshick/fast-rcnn

### 4. 概要

本文提出了Fast R-CNN模型，Fast R-CNN模型基于之前通过深度卷积网络对候选区域进行分类的工作，但是相比于之前的工作，Fast R-CNN中使用了单阶段（single-stage）的训练算法并且同时学习候选区域分类和区域修正两个任务。Fast R-CNN能够在提升训练和预测速度的同时，提高目标检测的准确率

### 5. 介绍

R-CNN的局限性

* 训练过程是多阶段流水线

  R-CNN首先使用log loss为卷积网络进行fine-tune，然后用卷积网络处理的到的特征训练SVM，最后训练得到区域回归器

* 训练需要大量的时间和存储空间

  对于SVM和区域回归器的训练，需要预先将图片区域对应的特征存储。这个过程需要花费大量的时间，并且占用大量的存储空间

* 目标检测速度慢

  在预测过程中，需要使用卷积网络对所有的候选区域进行处理，得到对应的特征

SPP-net通过SPP层加快了区域特征的提取速度，但是还是存在以下的限制

* SPP-net中也使用了多阶段流水线

* SPP-net中不能对SPP层前的卷积层进行微调，这一点限制了系统的准确性

### 6. 模型

Fast R-CNN的结构如图所示

![](/img/Fast_R-CNN/model_figure1.png)

Fast R-CNN通过Selective Search得到候选区域，从卷积网络处理的到的feature map中获取的到候选区域对应的feature map区域，转化为定长的特征，最后对特征训练分类器和回归器。其和之前工作的主要区别在于

1. 使用RoI pooling层代替了SSP

2. 同时训练分类器和回归器

#### 6.1 ROI pooling层
	ROI pooling层可以看作SPP的一种特殊形式（只使用一个pyramid level），其功能是将不同大小h*w的feature map转化为固定大小H*W的feature map，其工作原理为将h*w的feature map划分为H*W个大小为h/H*w/W的窗口，然后在每个窗口内进行最大池化（每个channel上单独进行）
 
#### 6.2 网络初始化
网络使用其他预训练好的网络（VGG-16），原始网络中最后一个最大池化层被替换为ROI pooling层，原始网络中输出层被替换为分类器和回归器对应的两个输出层

#### 6.3 对卷积层的微调

之间提到在SPP-net中无法对SPP层之前的卷积层进行微调，SPP-net训练过程中，每个batch的数据是来自于不同图片的候选区域（使用不相关的样本进行训练可以加快收敛速度），但由于feature map中每个RoI的感受野很大（通常对应整个原始图片），前向传播和反向传播的速度都需要对整个感受野进行处理，而由于batch中的候选区域来自不同的图片，对于每个样本都需要进行独立的前向传播和反向传播，这样整个训练过程会非常缓慢并占用很大的内存。

而在Fast R-CNN的训练过程中，每个batch的数据来自于N=2张图片中的R=128个候选区域（每个图片中采样64个候选区域），因此在前向传播和反向传播时，来自相同图片的候选区域可以共享内存以及计算过程（前向传播之需要使用卷积网络对两张图片进行处理，反向传播之需要在最后的conv feature map中对两张图片分别累加误差，再将两个累加的误差和在之前的卷积层中进行反向传播）。这种训练方式，能够显著地提升训练速度（64倍）。

注意到，这种做法使得batch样本的相关性提高，可能会降低收敛的速度，但是在实验中，这种现象并没有发生

#### 6.4 多任务学习误差

Fast R-CNN中同时学习分类器和回归器

分类器产生K+1个分类结果（+1指背景类），而回归器对K个目标都产生一个修正偏移量

![](/img/Fast_R-CNN/model_figure2.png)

最后的多任务学习的误差函数为

![](/img/Fast_R-CNN/model_figure3.png)

其中p是分类器预测结果，u是类别标签，v是bbox标签，$ t^u $ 是u对应的回归器的输出

为了减少回归器loss过大，通常会使用Huber loss

$ \lambda $是Iverson bracket indicator function，表示当条件符合为1。这里使用了$ u>=1 $，是因为背景的类别标签为0

![](/img/Fast_R-CNN/model_figure4.png)

#### 6.5 Mini-batch采样

每个mini-batch中含有N=2个图片中的候选区域，其中25%为正样本。正样本为和标签bbox IoU大于0.5的样本，负样本为IoU在[0.1, 0.5)之间的样本。

#### 6.6 RoI pooling层的误差反向传播

和max pooling层的误差反向传播相似，但是区别在于多个候选区域可能重叠，因此需要进行累加操作

![](/img/Fast_R-CNN/model_figure5.png)

#### 6.7 目标检测

Fast R-CNN在测试阶段可以进一步提高检测速度，做法是将最后的全连接层参数进行SVD分解

### 7. 实验结果

#### 7.1 检测准确率

VOC 2007 test

![](/img/Fast_R-CNN/exp_figure1.png)

VOC 2010 test

![](/img/Fast_R-CNN/exp_figure2.png)

VOC 2012 test

![](/img/Fast_R-CNN/exp_figure3.png)

#### 7.2 检测速度

![](/img/Fast_R-CNN/exp_figure4.png)

#### 7.3 Truncated SVD对性能影响

![](/img/Fast_R-CNN/exp_figure4.png)

文中还包含单阶段和多阶段的体系等的对比试验结果，详见原文